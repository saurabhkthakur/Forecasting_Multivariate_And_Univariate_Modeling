# -*- coding: utf-8 -*-
"""Base-analysis.ipynb

Automatically generated by Colaboratory.

"""

import numpy as np
import warnings
warnings.filterwarnings("ignore")
from statsmodels.tools.sm_exceptions import ConvergenceWarning
warnings.simplefilter('ignore', ConvergenceWarning)
from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima_model import ARMA
from prettytable import PrettyTable

from statsmodels.tsa.statespace.sarimax import SARIMAX

from itertools import product                    
from tqdm import tqdm_notebook

import keras
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import Dropout
from fbprophet import Prophet
from sklearn.linear_model import LinearRegression

from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.metrics import mean_squared_error, mean_squared_log_error

def weighted_mean_absolute_percentage_error(y_true, y_pred): 
    return np.sum(np.abs((y_true - y_pred) / y_true) * 100 * y_true)/np.sum(y_true)

from numpy.random import seed
seed(1)
import random
import tensorflow
tensorflow.random.set_seed(1)
os.environ['PYTHONHASHSEED']=str(1)
random.seed(1)

import argparse
ap = argparse.ArgumentParser()
ap.add_argument("-n", "--name",  help="Weekly or Monthly data")
args = vars(ap.parse_args())


"""# FUNCTION"""

def test_multivariate_split_sequences(sequences, n_steps):

	X = list()
	for i in range(len(sequences)):
		end_ix = i + n_steps

		if end_ix > len(sequences):
			break
		seq_x = sequences[i:end_ix]
		X.append(seq_x)
		
	return np.array(X)
 

def multivariate_split_sequences(sequences, n_steps):

	X, y = list(), list()
	for i in range(len(sequences)-2):
		end_ix = i + n_steps

		if end_ix > len(sequences):
			break
		seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix, -1]
		X.append(seq_x)
		y.append(seq_y)
	return np.array(X), np.array(y)
 
def lstmx_predictions(data,model, n_steps):

  pred=[]

  for i in range(0,len(data)):

  
    X = data[i][0:n_steps]
    X = X.reshape(1,n_steps,2)
    pred.append(model.predict(X, verbose=0))
  return np.array(pred)
  
  

def data_prep(sequence, n_steps, sent = None):
  X, y = list(), list()
  for i in range(len(sequence)):

    end_ix = i+n_steps
    if end_ix >= len(sequence):
      break

    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
    
    X.append(seq_x)
    y.append(seq_y)

  return np.array(X), np.array(y)


def predictions(data, n_steps,model):
  
  pred=[]
  model=model
  for i in range(0,len(data)):
    end_idx = i+n_steps
    if end_idx >= len(data):
      break
    X = data[i:end_idx]
    X = X.reshape(1,n_steps,1)
    pred.append(model.predict(X, verbose=0))
  return np.array(pred)


def forecast_metric(ytrue, pred,train_true,train_pred,X,model_used=None, prim_col=None, seco_col=None):
  
  '''
  ytrue - series of true of value
  pred - list of predictions
  model_used - model used
  prim col - primary column used
  seco_col = secondary column used
  X - table to store results
  '''


  WMAPE = weighted_mean_absolute_percentage_error(ytrue, pred)
  RMSE = np.sqrt(mean_squared_error(ytrue, pred))
  R2_sq = r2_score(ytrue, pred)
  MAE = mean_absolute_error(ytrue, pred)

  WMAPE_train = weighted_mean_absolute_percentage_error(train_true, train_pred)
  RMSE_train = np.sqrt(mean_squared_error(train_true, train_pred))
  R2_sq_train = r2_score(train_true, train_pred)
  MAE_train = mean_absolute_error(train_true, train_pred)  

  print('******************* testing **************')
  print('WMAPE',WMAPE)
  print('RMSE', RMSE)
  print('R2_square', R2_sq)
  print('MAE', MAE)
  
  print('******************* training **************')
  print('WMAPE',WMAPE_train)
  print('RMSE', RMSE_train)
  print('R2_square', R2_sq_train)
  print('MAE', MAE_train)

  X.add_row([model_used, prim_col, seco_col, np.round(WMAPE,2), np.round(RMSE,2), np.round(R2_sq,2), np.round(MAE,2), np.round(WMAPE_train,2), np.round(RMSE_train,2), np.round(R2_sq_train,2), np.round(MAE_train,2) ])

def optimizeARIMA(train_df):
 
  p = range(0, 3)
  d= range(0,2)
  q = range(0, 3)

  parameters = product(p,d,q)
  parameters_list = list(parameters)
  print(parameters_list)
  results = []
  best_aic = np.inf
  best_model = None
  best_param =None

  for param in tqdm_notebook(parameters_list):

    
    try:
      model=SARIMAX(train_df['Total_Sell_in'], order=(param[0], param[1], param[2])).fit(disp=-1)

    except:
      continue

    aic = model.aic

    if aic < best_aic:
      best_model = model
      best_aic = aic
      best_param = param

    results.append([param, model.aic])

  result_table = pd.DataFrame(results)
  result_table.columns = ['parameters', 'aic']
  result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)
  
  return result_table,best_param,best_model,best_aic


def optimizeSARIMA(train_df):
  

  ps = range(0, 3)
  d= range(0,2)
  qs = range(0, 3)
  Ps = range(0, 3 )
  D= range(0,2)
  Qs = range(0, 3)
  s = 5 # season length

  # creating list with all the possible combinations of parameters
  parameters = product(ps,d,qs,Ps,D,Qs)
  parameters_list = list(parameters)
  
    
  results = []
  best_aic = np.inf
  best_model = None
  best_param =None

  for param in tqdm_notebook(parameters_list):
      
      try:
          model=SARIMAX(train_df['Total_Sell_in'], order=(param[0], param[1], param[2]),seasonal_order=(param[3], param[4], param[5], s)).fit(disp=-1)
      except:
          continue
      aic = model.aic

      if aic < best_aic:
          best_model = model
          best_aic = aic
          best_param = param

      results.append([param, model.aic])

  result_table = pd.DataFrame(results)
  result_table.columns = ['parameters', 'aic']
  result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)
  
  return result_table,best_param,best_model,best_aic


dir='/content/drive/MyDrive/Sell_in_Twitter_Sentiment_google/output/'

def monthly_data_prep(df):
    
    def add_Str(x,y):
        return x+'_'+y
  
    mon_data = df.copy()
    mon_data['month'] = pd.to_datetime(mon_data['Date']).dt.strftime('%m')
    mon_data['year'] = pd.to_datetime(mon_data['Date']).dt.strftime('%y')
    mon_data['mon_year'] = mon_data.apply(lambda x : add_Str(x['month'], x['year']), axis=1 )

    def f(row):
        d={}
        for col in row.columns:
            if col.split('_')[0] == 'Total':
                d[col] = row[col].sum()
    
            elif col.split()[0] == 'Sentiment':
                d[col]=row[col].mean()

        return pd.Series(d)

    final_data = mon_data.groupby(['mon_year']).apply(f)
    final_data = final_data.reset_index()

    final_data['year'] = final_data['mon_year'].apply(lambda x:x.split('_')[1])
    final_data['month'] = final_data['mon_year'].apply(lambda x:x.split('_')[0])

    final_data = final_data.sort_values(by=['year','month'])
    final_data['Date'] = pd.date_range('2017-01-01', periods=36, freq='M')

    return final_data


def ptable_to_csv(table, filename, headers=True):
    """Save PrettyTable results to a CSV file.

    Adapted from @AdamSmith https://stackoverflow.com/questions/32128226

    :param PrettyTable table: Table object to get data from.
    :param str filename: Filepath for the output CSV.
    :param bool headers: Whether to include the header row in the CSV.
    :return: None
    """
    raw = table.get_string()
    data = [tuple(filter(None, map(str.strip, splitline)))
            for line in raw.splitlines()
            for splitline in [line.split('|')] if len(splitline) > 1]
    if table.title is not None:
        data = data[1:]
    if not headers:
        data = data[1:]
    with open(filename, 'w') as f:
        for d in data:
            f.write('{}\n'.format(','.join(d)))



def plot(df,dir,name, window=1):

  plt_df = df.copy()
  plt_df['year'] = pd.DatetimeIndex(df['Date']).year
  plt_df['month'] = pd.DatetimeIndex(df['Date']).month

  plt.figure(figsize = (15,8))
  sns.lineplot(plt_df.Date, plt_df.Total_Sell_in);
  print('**************',name)
  plt.savefig(dir+ name+'original_data.jpeg',bbox_inches='tight',pad_inches=2)

  plt.figure(figsize = (15,8))
  sns.lineplot(plt_df.month, plt_df.Total_Sell_in);
  print('**************',name)
  plt.savefig(dir+name +'Monthly_lineplot.jpeg',bbox_inches='tight',pad_inches=2)

  plt.figure(figsize = (15,8))
  sns.lineplot(plt_df.year, plt_df.Total_Sell_in);
  print('**************',name)
  plt.savefig(dir+name +'Yearly_lineplot.jpeg',bbox_inches='tight',pad_inches=2)


  fig = plt.figure(figsize=(15,8))
  sns.set(style='whitegrid')
  sns.lineplot(x='month', y='Total_Sell_in', hue='year',data=plt_df,palette=sns.color_palette("husl", 3));
  plt.savefig(dir+name +'Monthly_based_on_Yearly_lineplot.jpeg',bbox_inches='tight',pad_inches=2)

  plt.figure(figsize=(15,8))
  
  line1, =plt.plot(plt_df.Date,plt_df['Total_Sell_in'].rolling(window=window).mean(),label='rolling_mean')
  line2, =plt.plot(plt_df.Date,plt_df['Total_Sell_in'],label='original_plot')
  plt.legend([line1,line2])
  plt.savefig(dir+ name + 'Moving_avg vs original_plot.jpeg',bbox_inches='tight',pad_inches=2)






def MA_pred(df,train_df,test_df):
  print('MA')
  MA = ARMA(train_df['Total_Sell_in'], order=(0,2))
  MA = MA.fit()
  pred = MA.predict(len(train_df),len(df)-1)

  forecast_metric(test_df['Total_Sell_in'],pred,train_df['Total_Sell_in'].values,MA.predict(0,len(train_df)-1),x,model_used='MA',prim_col='Total_Sell_in',seco_col='Nan')
  df['MA'] = MA.predict(0,len(df)-1)



def ARIMA_pred(df,train_df,test_df,order):

  print('ARIMA')

  arimax = SARIMAX(train_df['Total_Sell_in'], order=order)
  arimax = arimax.fit(disp=False)
  pred = arimax.predict(len(train_df),len(df)-1)

  forecast_metric(test_df['Total_Sell_in'],pred,train_df['Total_Sell_in'].values,arimax.predict(0,len(train_df)-1),x,model_used='ARIMA',prim_col='Total_Sell_in',seco_col='Nan')
  df['ARIMA'] = arimax.predict(0,len(df)-1)




def ARIMAX_pred(df,train_df,test_df,order, exog =None):

  print('ARIMA'+exog)
  arimax = SARIMAX(train_df['Total_Sell_in'], order=order, exog=train_df[exog])
  arimax = arimax.fit()
  pred = arimax.predict(len(train_df),len(df)-1,exog=test_df[exog].values.reshape(len(test_df),1))

  forecast_metric(test_df['Total_Sell_in'],pred,train_df['Total_Sell_in'].values,arimax.predict(0,len(train_df)-1,exog=test_df[exog].values.reshape(len(test_df),1)),x,model_used='ARIMAX',prim_col='Total_Sell_in',seco_col=exog)
  df['ARIMAX+lag'+str(i)] = arimax.predict(0,len(df)-1,exog=test_df[exog].values.reshape(len(test_df),1))



def SARIMA_pred(df,train_df,test_df,order,seasonal_order):

  print('SARIMA')

  sarimax = SARIMAX(train_df['Total_Sell_in'], order=order,seasonal_order=seasonal_order)
  sarimax =sarimax.fit(disp=False)
  pred = sarimax.predict(len(train_df),len(df)-1)
  forecast_metric(test_df['Total_Sell_in'],pred,train_df['Total_Sell_in'].values,sarimax.predict(0,len(train_df)-1),x,model_used='SARIMA',prim_col='Total_Sell_in',seco_col='Nan')  
  df['SARIMA'] = sarimax.predict(0,len(df)-1)






def SARIMAX_pred(df,train_df,test_df,order,seasonal_order, exog =None):
  print('SARIMA'+exog)
  sarimax = SARIMAX(train_df['Total_Sell_in'], order=order,seasonal_order=seasonal_order, exog=train_df[exog])
  sarimax = sarimax.fit()
  pred = sarimax.predict(len(train_df),len(df)-1,exog=test_df[exog].values.reshape(len(test_df),1))
  
  forecast_metric(test_df['Total_Sell_in'],pred,train_df['Total_Sell_in'].values,sarimax.predict(0,len(train_df)-1,exog=test_df[exog].values.reshape(len(test_df),1)),x,model_used='SARIMAX',prim_col='Total_Sell_in',seco_col=exog)
  df['SARIMAX+lag'+str(i)] = sarimax.predict(0,len(df)-1,exog=test_df[exog].values.reshape(len(test_df),1))



def fbprophet_pred(df,train_df,test_df,freq,period=None):

  print('Fbprophet')
  prophet_df = train_df
  prophet_df = prophet_df.rename(columns={'Date':'ds', 'Total_Sell_in':'y'})
  m = Prophet()
  m = m.fit(prophet_df)
  future = m.make_future_dataframe(periods = period, freq=freq)
  forecast = m.predict(future)

  forecast_metric(test_df['Total_Sell_in'],forecast['yhat'][len(train_df):],train_df['Total_Sell_in'].values,forecast['yhat'][0:len(train_df)],x,model_used='Fb_prophet',prim_col='Total_Sell_in',seco_col='Nan')
  df['FB_Prophet'] = forecast['yhat']




def fbprophet_predx(df,train_df,test_df,freq,period=None, exog =None):
  print('FB'+exog)
  
  d = df.copy()
  d = d.rename(columns={'Date':'ds', 'Total_Sell_in':'y'})
  prophet_df = train_df
  prophet_df = prophet_df.rename(columns={'Date':'ds', 'Total_Sell_in':'y'})
  m = Prophet()
  m.add_regressor(exog)
  m = m.fit(prophet_df)

  future = m.make_future_dataframe(periods = period, freq=freq)
  future = future.merge(d, on='ds')
  forecast = m.predict(future)

  forecast_metric(test_df['Total_Sell_in'],forecast['yhat'][len(train_df):],train_df['Total_Sell_in'].values,forecast['yhat'][0:len(train_df)],x,model_used='Fb_prophet',prim_col='Total_Sell_in',seco_col=exog)
  df['FB_Prophet'] = forecast['yhat']


def linearRegression_pred(df,train_df,test_df,features,exog=None):
  print('Linear Regression')
  data = df[4:]
  train_data = data[:len(train_df)]
  test_data = data[len(train_df):]
  
  if exog == None:

    LR = LinearRegression()
    LR = LR.fit(train_data[features], train_data['Total_Sell_in'])

    pred = LR.predict(test_data[features])
    forecast_metric(test_data['Total_Sell_in'],pred,train_data['Total_Sell_in'].values,LR.predict(train_data[features]),x,model_used='LR',prim_col='Total_Sell_in',seco_col='Nan')
    pred_d = LR.predict(data[features])
    print(list([0,0,0,0])+list(pred_d))
    df['LR'] = list([0,0,0,0])+list(pred_d)

  else:

    features.append(exog)
    LR = LinearRegression()
    LR = LR.fit(train_data[features], train_data['Total_Sell_in'])

    pred = LR.predict(test_data[features])
    forecast_metric(test_data['Total_Sell_in'],pred,train_data['Total_Sell_in'].values,LR.predict(train_data[features]),x,model_used='LR',prim_col='Total_Sell_in'+exog,seco_col=exog)
    pred_d = LR.predict(data[features])
    print(list([0,0,0,0])+list(pred_d))
    df['LR'+exog] = list([0,0,0,0])+list(pred_d)



 

def LSTM_pred(df,train_df,test_df,n_steps=2,n_features=1):
  print('LSTM')

  data = train_df['Total_Sell_in'].values
 
  n_steps = n_steps
  X, y = data_prep(data, n_steps)
  n_features=1
  X = X.reshape((X.shape[0], X.shape[1], n_features))
  mape = keras.losses.MeanAbsolutePercentageError()

  model =Sequential()
  model.add(LSTM(200, activation='relu',return_sequences=True, input_shape = (n_steps,n_features)))
  model.add(LSTM(100, activation='relu'))
  model.add(Dense(1))
  model.compile(optimizer='adam', loss=mape)
  model.fit(X,y, epochs=1000)
  x_test = df['Total_Sell_in'][len(train_df)-n_steps:].values
  pred = predictions(x_test,n_steps,model=model)
  pred = pred.reshape(len(pred))
  train_pred = predictions(train_df['Total_Sell_in'].values,n_steps,model=model)
  train_pred = train_pred.reshape(len(train_pred))

  forecast_metric(df['Total_Sell_in'][len(train_df):],pred,df['Total_Sell_in'][n_steps:len(train_df)].values,train_pred,x,model_used='LSTM',prim_col='Total_Sell_in',seco_col='Nan')
  df['Lstm'] = list(df['Total_Sell_in'][:n_steps].values)+list(train_pred)+list(pred)




def Multivar_LSTM_pred(df,train_df,test_df,n_steps=2,n_features=2,exog=None):

  print('Multivarlstm'+exog)

  in_seq1 = train_df['Total_Sell_in'].values
  in_seq2 = train_df[exog].values
  out_seq = train_df['Total_Sell_in'].values
  in_seq1 = in_seq1.reshape((len(in_seq1), 1))
  in_seq2 = in_seq2.reshape((len(in_seq2), 1))
  out_seq = out_seq.reshape((len(out_seq), 1))
  dataset = np.hstack((in_seq1, in_seq2, out_seq))

 
  n_steps = n_steps
  X,y = multivariate_split_sequences(dataset,n_steps)
  n_features=X.shape[2]
  
  mape = keras.losses.MeanAbsolutePercentageError()

  model =Sequential()
  model.add(LSTM(200, activation='relu',return_sequences=True, input_shape = (n_steps,n_features)))
  model.add(LSTM(100, activation='relu'))
  model.add(Dense(1))
  model.compile(optimizer='adam', loss=mape)
  model.fit(X,y, epochs=1000)

  test_seq1 =  df['Total_Sell_in'][len(train_df)-n_steps:].values
  test_seq2 = df[exog][len(train_df)-n_steps:].values
  test_seq1 = test_seq1.reshape((len(test_seq1), 1))
  test_seq2 = test_seq2.reshape((len(test_seq2), 1))
  test_dataset = np.hstack((test_seq1, test_seq2))

  
  X_test = test_multivariate_split_sequences(test_dataset,n_steps) 
  pred = lstmx_predictions(X_test,model,n_steps)
  pred = pred.reshape(len(pred),1)
  test_pred=[]
  for i in range(len(pred)):
    test_pred.append(pred[i][0])

  train_seq1 = train_df['Total_Sell_in'].values
  train_seq2 = train_df[exog].values
  train_seq1 = train_seq1.reshape((len(train_seq1), 1))
  train_seq2 = train_seq2.reshape((len(train_seq2), 1))
  train_dataset = np.hstack((train_seq1, train_seq2))

  X_train = test_multivariate_split_sequences(train_dataset,n_steps)  

  train_pred = lstmx_predictions(X_train,model,n_steps)

  train_pred = train_pred.reshape(len(train_pred),1)
  train_pred_final = []
  for i in range(len(train_pred)):
    train_pred_final.append(train_pred[i][0])

 

  forecast_metric(df['Total_Sell_in'][len(train_df):],test_pred[:-1],df['Total_Sell_in'][n_steps:len(train_df)].values,train_pred_final[:-1],x,model_used='LSTM',prim_col='Total_Sell_in',seco_col=exog)
  df['Lstm'+exog] = list(df['Total_Sell_in'][:n_steps].values)+list(train_pred_final[:-1])+list(test_pred[:-1])

de = pd.read_csv('/content/drive/MyDrive/Sell_in_Twitter_Sentiment_google/Product_Sales_Sentiment.csv')
de.rename(columns={'week':'Date',
                   'total_sell_in':'Total_Sell_in',
                   'total_sell_in1':'Total_Sell_in1',
                   'total_sell_in2':'Total_Sell_in2',
                   'total_sell_in3':'Total_Sell_in3',
                   'total_sell_in4':'Total_Sell_in4',
                   'total_sell_in5':'Total_Sell_in5',
                   'sentiment':'Sentiment Lag 0',
                   'sentiment_1':'Sentiment Lag 1',
                   'sentiment_2':'Sentiment Lag 2',
                   'sentiment_3':'Sentiment Lag 3',
                   'sentiment_4':'Sentiment Lag 4',
                   'sentiment_5':'Sentiment Lag 5',      
                   },inplace=True)
print(de.columns)
de['Date']=de['Date'].apply(lambda x: x.replace('/','-'))
de.Date = pd.to_datetime(de['Date'], format='%m-%d-%Y')

result=[]
for i in de['Product'].value_counts().index:

  x = PrettyTable()
  x.field_names = ["Model", "Primary_Column", "Secondary_Column", "WMAPE","RMSE","R2 Squared", "MAE","WMAPE_Train","RMSE_Train","R2_Squared_Train","MAE_Train"]

  


  df =de[de.loc[:,'Product'] == i].reset_index(drop=True)
  
  if args['name'] == 'Monthly':  
    df = monthly_data_prep(df)
    name = 'Monthly'+i
    freq='M'
    n_steps=4
  elif args['name'] == 'Weekly':
    df=df
    name = 'Weekly'+i
    freq = 'W'
    n_steps=2
    
  train_length = int(0.7*len(df))
  test_length = len(df) - train_length
  
  train_df = df[:train_length]
  test_df = df[train_length:]
  print('shape:',train_df.shape,test_df.shape )
    
  plot(df,dir='/content/drive/MyDrive/Sell_in_Twitter_Sentiment_google/output/', name =name, window=4)
  
  _,ar_best_param,_,_ = optimizeARIMA(train_df)
  _,sr_best_param,_,_ = optimizeSARIMA(train_df)

  
  MA_pred(df,train_df,test_df)
  ARIMA_pred(df,train_df,test_df,ar_best_param)

  for i in range(0,6):
    ARIMAX_pred(df,train_df,test_df,ar_best_param,exog ='Sentiment Lag '+str(i))

  SARIMA_pred(df,train_df,test_df,order=(sr_best_param[0], sr_best_param[1], sr_best_param[2]), seasonal_order=(sr_best_param[3], sr_best_param[4], sr_best_param[5], 5))

  for i in range(0,6):
    SARIMAX_pred(df,train_df,test_df,order=(sr_best_param[0], sr_best_param[1], sr_best_param[2]), seasonal_order=(sr_best_param[3], sr_best_param[4], sr_best_param[5], 5), exog ='Sentiment Lag '+str(i))

  fbprophet_pred(df,train_df,test_df,freq,period=test_length)

  for i in range(0,6):
    fbprophet_predx(df,train_df,test_df,freq,period=test_length, exog ='Sentiment Lag '+str(i))

  linearRegression_pred(df,train_df,test_df,features=['Total_Sell_in1','Total_Sell_in2', 'Total_Sell_in3', 'Total_Sell_in4'],exog=None)
  linearRegression_pred(df,train_df,test_df,features=['Total_Sell_in1','Total_Sell_in2', 'Total_Sell_in3', 'Total_Sell_in4'],exog='Sentiment Lag 1')

  LSTM_pred(df,train_df,test_df,n_steps,n_features=1)
  
  for i in range(0,6):

    Multivar_LSTM_pred(df,train_df,test_df,n_steps=2,n_features=2,exog ='Sentiment Lag '+str(i))

  df.to_csv(dir+name+'pred_.csv')
  ptable_to_csv(x,dir+name+'metrics.csv')
  result.append(df)


